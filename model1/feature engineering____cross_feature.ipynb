{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from scipy.stats import entropy\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "import gc\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "def reduce_mem(df):\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    print('{:.2f} Mb, {:.2f} Mb ({:.2f} %)'.format(start_mem, end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    gc.collect()\n",
    "    return df\n",
    "\n",
    "import pickle\n",
    "path = 'D:\\\\ctr contest\\\\inter var\\\\before_feat_eng\\\\'\n",
    "\n",
    "file1 = open(path+'df.pkl','rb')\n",
    "df = pickle.load(file1)\n",
    "file1.close()\n",
    "\n",
    "file1 = open(path+'click_df.pkl','rb')\n",
    "click_df = pickle.load(file1)\n",
    "file1.close()\n",
    "\n",
    "file1 = open(path+'sort_df.pkl','rb')\n",
    "sort_df = pickle.load(file1)\n",
    "file1.close()\n",
    "\n",
    "file1 = open(path+'labels.pkl','rb')\n",
    "labels = pickle.load(file1)\n",
    "file1.close()\n",
    "\n",
    "file1 = open(path+'train_num.pkl','rb')\n",
    "train_num = pickle.load(file1)\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "\n",
    "print('=============================================== feat eng ===============================================')\n",
    "\n",
    "print('*************************** cross feat (second order) ***************************')\n",
    "# 二阶交叉特征，可以继续做更高阶的交叉。\n",
    "cross_cols = ['deviceid', 'newsid', 'pos', 'netmodel', 'lng_lat']\n",
    "for f in cross_cols:\n",
    "    for col in cross_cols:\n",
    "        if col == f:\n",
    "            continue\n",
    "        print('------------------ {} {} ------------------'.format(f, col))\n",
    "        df = df.merge(df[[f, col]].groupby(f, as_index=False)[col].agg({\n",
    "            'cross_{}_{}_nunique'.format(f, col): 'nunique',\n",
    "            'cross_{}_{}_ent'.format(f, col): lambda x: entropy(x.value_counts() / x.shape[0]) # 熵\n",
    "        }), on=f, how='left')\n",
    "        if 'cross_{}_{}_count'.format(f, col) not in df.columns.values and 'cross_{}_{}_count'.format(col, f) not in df.columns.values:\n",
    "            df = df.merge(df[[f, col, 'id']].groupby([f, col], as_index=False)['id'].agg({\n",
    "                'cross_{}_{}_count'.format(f, col): 'count' # 共现次数\n",
    "            }), on=[f, col], how='left')\n",
    "        if 'cross_{}_{}_count_ratio'.format(col, f) not in df.columns.values:\n",
    "            df['cross_{}_{}_count_ratio'.format(col, f)] = df['cross_{}_{}_count'.format(f, col)] / df[f + '_count'] # 比例偏好\n",
    "        if 'cross_{}_{}_count_ratio'.format(f, col) not in df.columns.values:\n",
    "            df['cross_{}_{}_count_ratio'.format(f, col)] = df['cross_{}_{}_count'.format(f, col)] / df[col + '_count'] # 比例偏好\n",
    "        df['cross_{}_{}_nunique_ratio_{}_count'.format(f, col, f)] = df['cross_{}_{}_nunique'.format(f, col)] / df[f + '_count']\n",
    "        print('runtime:', time.time() - t)\n",
    "    df = reduce_mem(df)\n",
    "del df['id']\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "\n",
    "print('=============================================== feat eng ===============================================')\n",
    "\n",
    "print('*************************** cross feat (third order) ***************************')\n",
    "# 二阶交叉特征，可以继续做更高阶的交叉。\n",
    "cross_cols = ['deviceid', 'newsid', 'pos', 'netmodel', 'lng_lat']\n",
    "\n",
    "cross_group_cols = []\n",
    "for ind in range(5):\n",
    "    for indj in range(ind+1,5):\n",
    "        cross_group_cols.append([cross_cols[ind], cross_cols[indj]])\n",
    "print(cross_group_cols)\n",
    "\n",
    "for f in cross_group_cols:\n",
    "    for col in cross_cols:\n",
    "        if col  in  f:\n",
    "            continue\n",
    "        if 'deviceid' in f and 'newsid' in f:\n",
    "            continue\n",
    "        if 'lng_lat' in f and 'newsid' in f:\n",
    "            continue\n",
    "            \n",
    "        print('------------------ {} {} ------------------'.format(f, col))\n",
    "        \n",
    "        df = df.merge(df[f+[col]].groupby(f, as_index=False)[col].agg({\n",
    "            'cross_{}_{}_nunique'.format(f, col): 'nunique',\n",
    "            'cross_{}_{}_ent'.format(f, col): lambda x: entropy(x.value_counts() / x.shape[0]) # 熵\n",
    "        }), on=f, how='left')\n",
    "        \n",
    "        count_three = ['cross_{}_{}_{}_count'.format(f[0], f[1], col), 'cross_{}_{}_{}_count'.format(f[0], col, f[1]),\n",
    "                       'cross_{}_{}_{}_count'.format(f[1], f[0], col), 'cross_{}_{}_{}_count'.format(f[1], col, f[0]),\n",
    "                       'cross_{}_{}_{}_count'.format(col, f[1], f[0]), 'cross_{}_{}_{}_count'.format(col, f[0], f[1])\n",
    "                      ]\n",
    "        flag = True\n",
    "        for cc in count_three:\n",
    "            if cc in df.columns.values :\n",
    "                flag = False\n",
    "                \n",
    "        if flag :\n",
    "            df = df.merge(df[f+[ col, 'id']].groupby(f+[col], as_index=False)['id'].agg({\n",
    "                'cross_{}_{}_{}_count'.format(f[0], f[1], col): 'count' # 共现次数\n",
    "            }), on=f+[col], how='left')\n",
    "            \n",
    "        for cc in count_three:\n",
    "            if cc in df.columns.values :\n",
    "                countfeat = cc\n",
    "                \n",
    "        if  'cross_{}_{}_{}_count_ratio'.format(f[0], f[1], col) not in df.columns.values and \\\n",
    "                'cross_{}_{}_{}_count_ratio'.format(f[1], f[0], col) not in df.columns.values:\n",
    "           \n",
    "            df[ 'cross_{}_{}_{}_count_ratio'.format(f[0], f[1], col)] = df[countfeat] / df[col + '_count'] # 比例偏好\n",
    "        \n",
    "        print('runtime:', time.time() - t)\n",
    "    df = reduce_mem(df)\n",
    "del df['id']\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_feat = []\n",
    "t = time.time()\n",
    "cross_cols = ['deviceid', 'newsid', 'pos', 'netmodel', 'lng_lat']\n",
    "perm_two = [i for i in itertools.permutations(cross_cols, 2)]\n",
    "pairs_count = []\n",
    "for pairs in perm_two:\n",
    "    print(pairs)\n",
    "    f = pairs[0]\n",
    "    col = pairs[1]\n",
    "    df = df.merge(df[[f, col, 'id']].groupby([f, col], as_index=False)['id'].agg({\n",
    "                'cross_{}_{}_count'.format(f, col): 'count' # 共现次数\n",
    "            }), on=[f, col], how='left')\n",
    "    \n",
    "    select_feat.append('cross_{}_{}_count'.format(f, col))\n",
    "    \n",
    "print('runtime:', time.time() - t)\n",
    "\n",
    "t = time.time()\n",
    "cross_cols = ['deviceid', 'newsid', 'pos', 'netmodel', 'lng_lat']\n",
    "perm_three = [i for i in itertools.permutations(cross_cols, 3)]\n",
    "pairs_count = []\n",
    "for pairs in perm_three:\n",
    "    print(pairs)\n",
    "    f = pairs[0]\n",
    "    col = pairs[1]\n",
    "    coll = pairs[2]\n",
    "    df = df.merge(df[[f, col,coll, 'id']].groupby([f, col,coll], as_index=False)['id'].agg({\n",
    "                'cross_{}_{}_{}_count'.format(f, col,coll): 'count' # 共现次数\n",
    "            }), on=[f, col, coll], how='left')\n",
    "    \n",
    "    select_feat.append('cross_{}_{}_{}_count'.format(f, col,coll))\n",
    "print('runtime:', time.time() - t)\n",
    "\n",
    "pairs_count = df[select_feat]\n",
    "\n",
    "out = 'D:\\\\ctr contest\\\\inter var\\\\pairs_count\\\\'\n",
    "file1 = open(out+'pairs_count.pkl','wb')\n",
    "pickle.dump(pairs_count, file1, protocol = 4)\n",
    "file1.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "import itertools\n",
    "\n",
    "print('=============================================== feat eng ===============================================')\n",
    "\n",
    "print('*************************** cross feat (fourth order) ***************************')\n",
    "# 二阶交叉特征，可以继续做更高阶的交叉。\n",
    "cross_cols = ['deviceid', 'newsid', 'pos', 'netmodel', 'lng_lat']\n",
    "\n",
    "cross_group_cols = []\n",
    "for ind in range(5):\n",
    "    for indj in range(ind+1,5):\n",
    "        for indk in range(indj+1,5):\n",
    "            cross_group_cols.append([cross_cols[ind], cross_cols[indj], cross_cols[indk]])\n",
    "            \n",
    "for f in cross_group_cols:\n",
    "    for col in cross_cols:\n",
    "            \n",
    "        if col  in  f:\n",
    "            continue\n",
    "        if 'deviceid' in f and 'newsid' in f:\n",
    "            continue\n",
    "        if 'lng_lat' in f and 'newsid' in f:\n",
    "            continue\n",
    "        \n",
    "        print('------------------ {} {} ------------------'.format(f, col))\n",
    "        \n",
    "        df = df.merge(df[f+[col]].groupby(f, as_index=False)[col].agg({\n",
    "            'cross_{}_{}_nunique'.format(f, col): 'nunique',\n",
    "            'cross_{}_{}_ent'.format(f, col): lambda x: entropy(x.value_counts() / x.shape[0]) # 熵\n",
    "        }), on=f, how='left')\n",
    "        \n",
    "#         print(len([i for i in itertools.permutations(f+[col], 4)]))\n",
    "        perm = [i for i in itertools.permutations(f+[col], 4)]\n",
    "#         print(perm)\n",
    "\n",
    "        \n",
    "        count_four = ['cross_{}_{}_{}_{}_count'.format(j[0], j[1], j[2], j[3]) for j in perm]\n",
    "\n",
    "        flag = True\n",
    "        for cc in count_four:\n",
    "            if cc in df.columns.values :\n",
    "                flag = False\n",
    "        if flag :\n",
    "            df = df.merge(df[f+[ col, 'id']].groupby(f+[col], as_index=False)['id'].agg({\n",
    "                'cross_{}_{}_{}_{}_count'.format(f[0], f[1], f[2], col): 'count' # 共现次数\n",
    "            }), on=f+[col], how='left')\n",
    "            \n",
    "        for cc in count_four:\n",
    "            if cc in df.columns.values :\n",
    "                countfeat = cc\n",
    "\n",
    "        judge = []\n",
    "        for m in itertools.permutations(f, 3):\n",
    "            judge.append('cross_{}_{}_{}_{}_count_ratio'.format(m[0], m[1], m[2] ,col) )\n",
    "        judge_flag = True\n",
    "        for jud in judge:\n",
    "            if jud in df.columns.values:\n",
    "                judge_flag =False\n",
    "        if judge_flag:\n",
    "            df[ 'cross_{}_{}_{}_{}_count_ratio'.format(f[0], f[1],f[2] ,col)] = df[countfeat] / df[col + '_count'] # 比例偏好\n",
    "        \n",
    "        comb_two = [k for k in itertools.combinations(f+[col], 2)]\n",
    "        for ct in comb_two:\n",
    "            df[ 'cross_{}_{}_{}_{}_{}_{}_count_ratio'.format(f[0], f[1],f[2] ,col,ct[0], ct[1])] = df[countfeat] / paircount[ct[0]+'_'+ct[1] + '_count']\n",
    "        \n",
    "        comb_three = [k for k in itertools.combinations(f+[col], 3)]\n",
    "        for cth in comb_three:\n",
    "            df[ 'cross_{}_{}_{}_{}_{}_{}_{}_count_ratio'.format(f[0], f[1],f[2] ,col,cth[0], cth[1], cth[2])] = df[countfeat] / paircount[cth[0]+'_'+cth[1]+'_'+cth[2] + '_count']\n",
    "        \n",
    "        df['cross_{}_{}_nunique_ratio_{}_count'.format(f, col, f)] = df['cross_{}_{}_nunique'.format(f, col)] / paircount[f[0]+'_'+f[1]+'_'+f[2] + '_count']\n",
    "       \n",
    "        print('runtime:', time.time() - t)\n",
    "df = reduce_mem(df)\n",
    "del df['id']\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = 'D:\\\\ctr contest\\\\inter var\\\\features\\\\'\n",
    "file1 = open(out+'cross_feature.pkl','wb')\n",
    "pickle.dump(df[df.columns.to_list()[26:]], file1, protocol = 4)\n",
    "file1.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
